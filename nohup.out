Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_96         Model:              iTransformer        

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/all_datasets/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       50                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type4               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

[1mOthers[0m
  RAG:                0                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_96_iTransformer_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3423884
	speed: 0.0400s/iter; left time: 526.0177s
	iters: 200, epoch: 1 | loss: 0.3193010
	speed: 0.0267s/iter; left time: 348.2530s
Epoch: 1 cost time: 8.21314024925232
Epoch: 1, Steps: 265 | Train Loss: 0.3783065 Vali Loss: 0.6825350 Test Loss: 0.3861638
Validation loss decreased (inf --> 0.682535).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4687119
	speed: 0.0538s/iter; left time: 693.0686s
	iters: 200, epoch: 2 | loss: 0.3490449
	speed: 0.0248s/iter; left time: 317.6211s
Epoch: 2 cost time: 6.093039512634277
Epoch: 2, Steps: 265 | Train Loss: 0.3424210 Vali Loss: 0.6934112 Test Loss: 0.3897198
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.3014521
	speed: 0.0786s/iter; left time: 991.5238s
	iters: 200, epoch: 3 | loss: 0.2929958
	speed: 0.0300s/iter; left time: 375.7293s
Epoch: 3 cost time: 8.170752763748169
Epoch: 3, Steps: 265 | Train Loss: 0.3232869 Vali Loss: 0.7016388 Test Loss: 0.3974510
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.3184435
	speed: 0.0740s/iter; left time: 914.1703s
	iters: 200, epoch: 4 | loss: 0.3560541
	speed: 0.0297s/iter; left time: 364.2528s
Epoch: 4 cost time: 7.910617113113403
Epoch: 4, Steps: 265 | Train Loss: 0.3065379 Vali Loss: 0.7257282 Test Loss: 0.4017796
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 5 | loss: 0.2886788
	speed: 0.0733s/iter; left time: 886.4161s
	iters: 200, epoch: 5 | loss: 0.3371134
	speed: 0.0237s/iter; left time: 284.4219s
Epoch: 5 cost time: 6.181053876876831
Epoch: 5, Steps: 265 | Train Loss: 0.2917463 Vali Loss: 0.7122363 Test Loss: 0.4086013
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 6 | loss: 0.2592053
	speed: 0.0372s/iter; left time: 440.4304s
	iters: 200, epoch: 6 | loss: 0.2635512
	speed: 0.0177s/iter; left time: 207.9298s
Epoch: 6 cost time: 5.362539768218994
Epoch: 6, Steps: 265 | Train Loss: 0.2795410 Vali Loss: 0.7281126 Test Loss: 0.4254385
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 7 | loss: 0.2552418
	speed: 0.0761s/iter; left time: 880.1241s
	iters: 200, epoch: 7 | loss: 0.2606699
	speed: 0.0305s/iter; left time: 349.1254s
Epoch: 7 cost time: 8.231237888336182
Epoch: 7, Steps: 265 | Train Loss: 0.2674196 Vali Loss: 0.7499340 Test Loss: 0.4188528
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 8 | loss: 0.2824488
	speed: 0.0766s/iter; left time: 865.3396s
	iters: 200, epoch: 8 | loss: 0.2747308
	speed: 0.0296s/iter; left time: 331.2914s
Epoch: 8 cost time: 8.163885354995728
Epoch: 8, Steps: 265 | Train Loss: 0.2569841 Vali Loss: 0.7663511 Test Loss: 0.4411505
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 9 | loss: 0.2493875
	speed: 0.0738s/iter; left time: 814.5939s
	iters: 200, epoch: 9 | loss: 0.2440096
	speed: 0.0251s/iter; left time: 274.8759s
Epoch: 9 cost time: 6.860591888427734
Epoch: 9, Steps: 265 | Train Loss: 0.2464424 Vali Loss: 0.7615767 Test Loss: 0.4366657
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 10 | loss: 0.2250134
	speed: 0.0460s/iter; left time: 495.0952s
	iters: 200, epoch: 10 | loss: 0.2380116
	speed: 0.0136s/iter; left time: 145.3618s
Epoch: 10 cost time: 4.773120641708374
Epoch: 10, Steps: 265 | Train Loss: 0.2371578 Vali Loss: 0.7795580 Test Loss: 0.4393901
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 11 | loss: 0.2401817
	speed: 0.0733s/iter; left time: 770.1046s
	iters: 200, epoch: 11 | loss: 0.2225434
	speed: 0.0293s/iter; left time: 304.5439s
Epoch: 11 cost time: 8.170691967010498
Epoch: 11, Steps: 265 | Train Loss: 0.2302354 Vali Loss: 0.7570503 Test Loss: 0.4420167
EarlyStopping counter: 10 out of 10
Early stopping
Traceback (most recent call last):
  File "/home/tengshiyuan/code/Time-Series-Library/run.py", line 416, in <module>
    exp.train(setting)
  File "/home/tengshiyuan/code/Time-Series-Library/exp/exp_long_term_forecasting.py", line 287, in train
    self.model.load_state_dict(torch.load(best_model_path))
  File "/home/tengshiyuan/miniconda3/envs/graph/lib/python3.10/site-packages/torch/serialization.py", line 997, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/tengshiyuan/miniconda3/envs/graph/lib/python3.10/site-packages/torch/serialization.py", line 444, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/tengshiyuan/miniconda3/envs/graph/lib/python3.10/site-packages/torch/serialization.py", line 425, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/long_term_forecast_ETTh1_96_96_iTransformer_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm/checkpoint.pth'
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_96         Model:              iTransformer        

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/all_datasets/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       50                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type4               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

[1mOthers[0m
  RAG:                1                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_96_iTransformer_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm_rag>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.1939573
	speed: 0.0985s/iter; left time: 1295.8379s
	iters: 200, epoch: 1 | loss: 0.0963417
	speed: 0.1339s/iter; left time: 1747.4174s
Epoch: 1 cost time: 32.220274686813354
Epoch: 1, Steps: 265 | Train Loss: 0.1439036 Vali Loss: 1.0645167 Test Loss: 0.6762637
Validation loss decreased (inf --> 1.064517).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 2 | loss: 0.1325525
	speed: 0.2181s/iter; left time: 2809.8443s
	iters: 200, epoch: 2 | loss: 0.0963242
	speed: 0.1269s/iter; left time: 1622.5620s
Epoch: 2 cost time: 31.22070002555847
Epoch: 2, Steps: 265 | Train Loss: 0.1328033 Vali Loss: 0.9981262 Test Loss: 0.6480797
Validation loss decreased (1.064517 --> 0.998126).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 3 | loss: 0.0850380
	speed: 0.2394s/iter; left time: 3021.9734s
	iters: 200, epoch: 3 | loss: 0.0860955
	speed: 0.0980s/iter; left time: 1226.8370s
Epoch: 3 cost time: 31.739654302597046
Epoch: 3, Steps: 265 | Train Loss: 0.1131168 Vali Loss: 0.8422021 Test Loss: 0.5122071
Validation loss decreased (0.998126 --> 0.842202).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 4 | loss: 0.0961199
	speed: 0.3053s/iter; left time: 3772.7520s
	iters: 200, epoch: 4 | loss: 0.1076790
	speed: 0.1257s/iter; left time: 1541.1396s
Epoch: 4 cost time: 38.74603462219238
Epoch: 4, Steps: 265 | Train Loss: 0.1085700 Vali Loss: 0.8435795 Test Loss: 0.5125509
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 5 | loss: 0.0945393
	speed: 0.2932s/iter; left time: 3545.0493s
	iters: 200, epoch: 5 | loss: 0.5322728
	speed: 0.1478s/iter; left time: 1771.6864s
Epoch: 5 cost time: 37.19597291946411
Epoch: 5, Steps: 265 | Train Loss: 0.1038969 Vali Loss: 0.7992554 Test Loss: 0.4885564
Validation loss decreased (0.842202 --> 0.799255).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 6 | loss: 0.2312571
	speed: 0.2090s/iter; left time: 2471.3659s
	iters: 200, epoch: 6 | loss: 0.0835697
	speed: 0.1278s/iter; left time: 1498.9216s
Epoch: 6 cost time: 34.29249024391174
Epoch: 6, Steps: 265 | Train Loss: 0.1125191 Vali Loss: 0.7939085 Test Loss: 0.4830260
Validation loss decreased (0.799255 --> 0.793908).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 7 | loss: 0.0832439
	speed: 0.1971s/iter; left time: 2278.1396s
	iters: 200, epoch: 7 | loss: 0.1040380
	speed: 0.1307s/iter; left time: 1497.6216s
Epoch: 7 cost time: 30.2727632522583
Epoch: 7, Steps: 265 | Train Loss: 0.1085919 Vali Loss: 0.8407505 Test Loss: 0.5289717
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 8 | loss: 0.1073589
	speed: 0.2124s/iter; left time: 2399.6834s
	iters: 200, epoch: 8 | loss: 0.0995185
	speed: 0.0939s/iter; left time: 1051.3560s
Epoch: 8 cost time: 28.190675735473633
Epoch: 8, Steps: 265 | Train Loss: 0.1114791 Vali Loss: 0.8969952 Test Loss: 0.5739371
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 9 | loss: 0.1044081
	speed: 0.2503s/iter; left time: 2760.7082s
	iters: 200, epoch: 9 | loss: 0.1048930
	speed: 0.0880s/iter; left time: 962.3722s
Epoch: 9 cost time: 30.67481803894043
Epoch: 9, Steps: 265 | Train Loss: 0.1185553 Vali Loss: 0.8965975 Test Loss: 0.5620570
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 10 | loss: 0.0919727
	speed: 0.2480s/iter; left time: 2670.0330s
	iters: 200, epoch: 10 | loss: 0.0893080
	speed: 0.1135s/iter; left time: 1211.0283s
Epoch: 10 cost time: 30.28937268257141
Epoch: 10, Steps: 265 | Train Loss: 0.1051696 Vali Loss: 0.8393829 Test Loss: 0.5115197
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 11 | loss: 0.0876724
	speed: 0.2170s/iter; left time: 2278.6265s
	iters: 200, epoch: 11 | loss: 0.0823283
	speed: 0.1287s/iter; left time: 1338.2258s
Epoch: 11 cost time: 32.2991418838501
Epoch: 11, Steps: 265 | Train Loss: 0.0967757 Vali Loss: 0.8011046 Test Loss: 0.4820774
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_96_iTransformer_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm_rag<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.483418732881546, mae:0.46092909574508667, dtw:Not calculated
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_96         Model:              DLinear             

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/all_datasets/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       50                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type4               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

[1mOthers[0m
  RAG:                0                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_96_DLinear_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.4814817
	speed: 0.0162s/iter; left time: 213.1216s
	iters: 200, epoch: 1 | loss: 0.3683055
	speed: 0.0069s/iter; left time: 90.4235s
Epoch: 1 cost time: 2.756943941116333
Epoch: 1, Steps: 265 | Train Loss: 0.4329466 Vali Loss: 0.7311878 Test Loss: 0.4326458
Validation loss decreased (inf --> 0.731188).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3638648
	speed: 0.0219s/iter; left time: 282.1841s
	iters: 200, epoch: 2 | loss: 0.3313819
	speed: 0.0033s/iter; left time: 42.7296s
Epoch: 2 cost time: 1.104788064956665
Epoch: 2, Steps: 265 | Train Loss: 0.3753225 Vali Loss: 0.6856843 Test Loss: 0.4044838
Validation loss decreased (0.731188 --> 0.685684).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.3569056
	speed: 0.0295s/iter; left time: 371.8755s
	iters: 200, epoch: 3 | loss: 0.3718042
	speed: 0.0072s/iter; left time: 90.1716s
Epoch: 3 cost time: 3.1145026683807373
Epoch: 3, Steps: 265 | Train Loss: 0.3638130 Vali Loss: 0.6744919 Test Loss: 0.3958654
Validation loss decreased (0.685684 --> 0.674492).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.3093284
	speed: 0.0322s/iter; left time: 397.9837s
	iters: 200, epoch: 4 | loss: 0.3107321
	speed: 0.0074s/iter; left time: 90.3075s
Epoch: 4 cost time: 2.2339184284210205
Epoch: 4, Steps: 265 | Train Loss: 0.3589858 Vali Loss: 0.6700085 Test Loss: 0.3914710
Validation loss decreased (0.674492 --> 0.670008).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 5 | loss: 0.3068677
	speed: 0.0316s/iter; left time: 381.7058s
	iters: 200, epoch: 5 | loss: 0.3248728
	speed: 0.0073s/iter; left time: 87.4742s
Epoch: 5 cost time: 2.1669280529022217
Epoch: 5, Steps: 265 | Train Loss: 0.3557378 Vali Loss: 0.6609984 Test Loss: 0.3903877
Validation loss decreased (0.670008 --> 0.660998).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 6 | loss: 0.3677261
	speed: 0.0309s/iter; left time: 365.6749s
	iters: 200, epoch: 6 | loss: 0.3500445
	speed: 0.0077s/iter; left time: 89.7926s
Epoch: 6 cost time: 2.239262342453003
Epoch: 6, Steps: 265 | Train Loss: 0.3541134 Vali Loss: 0.6793995 Test Loss: 0.3872282
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 7 | loss: 0.3932856
	speed: 0.0336s/iter; left time: 388.1875s
	iters: 200, epoch: 7 | loss: 0.3336456
	speed: 0.0073s/iter; left time: 83.3751s
Epoch: 7 cost time: 2.237264633178711
Epoch: 7, Steps: 265 | Train Loss: 0.3520834 Vali Loss: 0.6722966 Test Loss: 0.3873897
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 8 | loss: 0.3932572
	speed: 0.0314s/iter; left time: 354.8291s
	iters: 200, epoch: 8 | loss: 0.3417056
	speed: 0.0069s/iter; left time: 76.9282s
Epoch: 8 cost time: 1.9611833095550537
Epoch: 8, Steps: 265 | Train Loss: 0.3537258 Vali Loss: 0.6648026 Test Loss: 0.3865069
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 9 | loss: 0.3686067
	speed: 0.0254s/iter; left time: 279.8180s
	iters: 200, epoch: 9 | loss: 0.3430907
	speed: 0.0034s/iter; left time: 37.1714s
Epoch: 9 cost time: 1.1004393100738525
Epoch: 9, Steps: 265 | Train Loss: 0.3561564 Vali Loss: 0.6580457 Test Loss: 0.3853813
Validation loss decreased (0.660998 --> 0.658046).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 10 | loss: 0.3777459
	speed: 0.0184s/iter; left time: 198.1090s
	iters: 200, epoch: 10 | loss: 0.3068927
	speed: 0.0067s/iter; left time: 71.8241s
Epoch: 10 cost time: 1.9192945957183838
Epoch: 10, Steps: 265 | Train Loss: 0.3493456 Vali Loss: 0.6569771 Test Loss: 0.3847932
Validation loss decreased (0.658046 --> 0.656977).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 11 | loss: 0.2870732
	speed: 0.0335s/iter; left time: 351.7659s
	iters: 200, epoch: 11 | loss: 0.3568116
	speed: 0.0075s/iter; left time: 78.0694s
Epoch: 11 cost time: 2.227975368499756
Epoch: 11, Steps: 265 | Train Loss: 0.3500041 Vali Loss: 0.6612815 Test Loss: 0.3835535
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 12 | loss: 0.3108737
	speed: 0.0323s/iter; left time: 330.8755s
	iters: 200, epoch: 12 | loss: 0.3849857
	speed: 0.0079s/iter; left time: 80.5294s
Epoch: 12 cost time: 2.230806589126587
Epoch: 12, Steps: 265 | Train Loss: 0.3497615 Vali Loss: 0.6620172 Test Loss: 0.3842246
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 13 | loss: 0.3143002
	speed: 0.0329s/iter; left time: 328.5038s
	iters: 200, epoch: 13 | loss: 0.3904944
	speed: 0.0076s/iter; left time: 74.7684s
Epoch: 13 cost time: 2.2284727096557617
Epoch: 13, Steps: 265 | Train Loss: 0.3481037 Vali Loss: 0.6611252 Test Loss: 0.3834356
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 14 | loss: 0.3344396
	speed: 0.0317s/iter; left time: 307.4382s
	iters: 200, epoch: 14 | loss: 0.3543409
	speed: 0.0072s/iter; left time: 69.4139s
Epoch: 14 cost time: 2.156636953353882
Epoch: 14, Steps: 265 | Train Loss: 0.3483257 Vali Loss: 0.6672302 Test Loss: 0.3837747
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 15 | loss: 0.3792314
	speed: 0.0297s/iter; left time: 280.4528s
	iters: 200, epoch: 15 | loss: 0.2932341
	speed: 0.0066s/iter; left time: 61.2293s
Epoch: 15 cost time: 1.975339651107788
Epoch: 15, Steps: 265 | Train Loss: 0.3475527 Vali Loss: 0.6544318 Test Loss: 0.3832477
Validation loss decreased (0.656977 --> 0.654432).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 16 | loss: 0.3110932
	speed: 0.0229s/iter; left time: 210.1509s
	iters: 200, epoch: 16 | loss: 0.4295910
	speed: 0.0034s/iter; left time: 30.6412s
Epoch: 16 cost time: 1.1104934215545654
Epoch: 16, Steps: 265 | Train Loss: 0.3472129 Vali Loss: 0.6634502 Test Loss: 0.3827017
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 17 | loss: 0.3722540
	speed: 0.0166s/iter; left time: 148.0537s
	iters: 200, epoch: 17 | loss: 0.3487882
	speed: 0.0034s/iter; left time: 29.7321s
Epoch: 17 cost time: 1.1211833953857422
Epoch: 17, Steps: 265 | Train Loss: 0.3502427 Vali Loss: 0.6655452 Test Loss: 0.3833289
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 18 | loss: 0.3309364
	speed: 0.0227s/iter; left time: 196.3624s
	iters: 200, epoch: 18 | loss: 0.3099021
	speed: 0.0079s/iter; left time: 67.7116s
Epoch: 18 cost time: 2.2554714679718018
Epoch: 18, Steps: 265 | Train Loss: 0.3471216 Vali Loss: 0.6651620 Test Loss: 0.3829660
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 19 | loss: 0.3902606
	speed: 0.0346s/iter; left time: 289.7130s
	iters: 200, epoch: 19 | loss: 0.3198574
	speed: 0.0073s/iter; left time: 60.4722s
Epoch: 19 cost time: 2.201312780380249
Epoch: 19, Steps: 265 | Train Loss: 0.3474694 Vali Loss: 0.6691456 Test Loss: 0.3827304
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 20 | loss: 0.3914895
	speed: 0.0316s/iter; left time: 256.4637s
	iters: 200, epoch: 20 | loss: 0.3075507
	speed: 0.0078s/iter; left time: 62.6047s
Epoch: 20 cost time: 2.2508602142333984
Epoch: 20, Steps: 265 | Train Loss: 0.3475979 Vali Loss: 0.6550291 Test Loss: 0.3833389
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 21 | loss: 0.3346456
	speed: 0.0339s/iter; left time: 266.0758s
	iters: 200, epoch: 21 | loss: 0.3400607
	speed: 0.0068s/iter; left time: 52.3959s
Epoch: 21 cost time: 2.141155242919922
Epoch: 21, Steps: 265 | Train Loss: 0.3478404 Vali Loss: 0.6694515 Test Loss: 0.3833546
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 22 | loss: 0.3049495
	speed: 0.0332s/iter; left time: 251.6280s
	iters: 200, epoch: 22 | loss: 0.3176353
	speed: 0.0071s/iter; left time: 52.8128s
Epoch: 22 cost time: 2.1567039489746094
Epoch: 22, Steps: 265 | Train Loss: 0.3475345 Vali Loss: 0.6608608 Test Loss: 0.3822157
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 23 | loss: 0.2736096
	speed: 0.0299s/iter; left time: 218.7298s
	iters: 200, epoch: 23 | loss: 0.3174360
	speed: 0.0069s/iter; left time: 49.9021s
Epoch: 23 cost time: 1.8588271141052246
Epoch: 23, Steps: 265 | Train Loss: 0.3466831 Vali Loss: 0.6521961 Test Loss: 0.3842229
Validation loss decreased (0.654432 --> 0.652196).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 24 | loss: 0.3481859
	speed: 0.0165s/iter; left time: 116.5319s
	iters: 200, epoch: 24 | loss: 0.3288303
	speed: 0.0033s/iter; left time: 22.8775s
Epoch: 24 cost time: 1.0915844440460205
Epoch: 24, Steps: 265 | Train Loss: 0.3464101 Vali Loss: 0.6603941 Test Loss: 0.3821065
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 25 | loss: 0.3431307
	speed: 0.0283s/iter; left time: 192.3174s
	iters: 200, epoch: 25 | loss: 0.4732119
	speed: 0.0074s/iter; left time: 49.4754s
Epoch: 25 cost time: 2.220269203186035
Epoch: 25, Steps: 265 | Train Loss: 0.3464406 Vali Loss: 0.6529171 Test Loss: 0.3828095
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 26 | loss: 0.4046292
	speed: 0.0318s/iter; left time: 207.8132s
	iters: 200, epoch: 26 | loss: 0.3841049
	speed: 0.0075s/iter; left time: 47.9948s
Epoch: 26 cost time: 2.192495346069336
Epoch: 26, Steps: 265 | Train Loss: 0.3471317 Vali Loss: 0.6774951 Test Loss: 0.3820144
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 27 | loss: 0.3041362
	speed: 0.0311s/iter; left time: 194.8574s
	iters: 200, epoch: 27 | loss: 0.3370350
	speed: 0.0071s/iter; left time: 43.7806s
Epoch: 27 cost time: 2.1377010345458984
Epoch: 27, Steps: 265 | Train Loss: 0.3467663 Vali Loss: 0.6630194 Test Loss: 0.3823830
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 28 | loss: 0.4443502
	speed: 0.0330s/iter; left time: 197.7328s
	iters: 200, epoch: 28 | loss: 0.2948315
	speed: 0.0071s/iter; left time: 41.9713s
Epoch: 28 cost time: 2.3447747230529785
Epoch: 28, Steps: 265 | Train Loss: 0.3467087 Vali Loss: 0.6633489 Test Loss: 0.3820839
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 29 | loss: 0.3781963
	speed: 0.0340s/iter; left time: 194.8520s
	iters: 200, epoch: 29 | loss: 0.3487973
	speed: 0.0052s/iter; left time: 29.2755s
Epoch: 29 cost time: 1.988008975982666
Epoch: 29, Steps: 265 | Train Loss: 0.3462145 Vali Loss: 0.6559328 Test Loss: 0.3825693
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 30 | loss: 0.3270449
	speed: 0.0296s/iter; left time: 161.5241s
	iters: 200, epoch: 30 | loss: 0.4328554
	speed: 0.0036s/iter; left time: 19.1127s
Epoch: 30 cost time: 1.4553310871124268
Epoch: 30, Steps: 265 | Train Loss: 0.3478270 Vali Loss: 0.6642592 Test Loss: 0.3818091
EarlyStopping counter: 7 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 31 | loss: 0.3119562
	speed: 0.0158s/iter; left time: 82.1801s
	iters: 200, epoch: 31 | loss: 0.3560210
	speed: 0.0032s/iter; left time: 16.3824s
Epoch: 31 cost time: 1.0754189491271973
Epoch: 31, Steps: 265 | Train Loss: 0.3468594 Vali Loss: 0.6583598 Test Loss: 0.3824012
EarlyStopping counter: 8 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 32 | loss: 0.3367947
	speed: 0.0266s/iter; left time: 131.3019s
	iters: 200, epoch: 32 | loss: 0.3773252
	speed: 0.0074s/iter; left time: 35.9727s
Epoch: 32 cost time: 2.1851646900177
Epoch: 32, Steps: 265 | Train Loss: 0.3467018 Vali Loss: 0.6743047 Test Loss: 0.3816785
EarlyStopping counter: 9 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 33 | loss: 0.3223029
	speed: 0.0325s/iter; left time: 151.6670s
	iters: 200, epoch: 33 | loss: 0.2867773
	speed: 0.0072s/iter; left time: 33.0650s
Epoch: 33 cost time: 2.041449785232544
Epoch: 33, Steps: 265 | Train Loss: 0.3458347 Vali Loss: 0.6568590 Test Loss: 0.3826116
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_96_DLinear_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.3840319514274597, mae:0.39758235216140747, dtw:Not calculated
Using GPU
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           ETTh1_96_96         Model:              DLinear             

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/all_datasets/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          48                  
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       50                  Batch Size:         32                  
  Patience:           5                   Learning Rate:      0.0001              
  Des:                Exp                 Loss:               MSE                 
  Lradj:              type4               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

[1mOthers[0m
  RAG:                1                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_ETTh1_96_96_DLinear_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm_rag>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.1139104
	speed: 0.0569s/iter; left time: 748.8366s
	iters: 200, epoch: 1 | loss: 0.1787206
	speed: 0.0410s/iter; left time: 534.7267s
Epoch: 1 cost time: 12.569092750549316
Epoch: 1, Steps: 265 | Train Loss: 0.1608755 Vali Loss: 1.0140433 Test Loss: 0.6204700
Validation loss decreased (inf --> 1.014043).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 2 | loss: 0.0988461
	speed: 0.0768s/iter; left time: 990.2400s
	iters: 200, epoch: 2 | loss: 0.2145960
	speed: 0.0196s/iter; left time: 250.0117s
Epoch: 2 cost time: 5.610082387924194
Epoch: 2, Steps: 265 | Train Loss: 0.1313400 Vali Loss: 0.9527940 Test Loss: 0.5770732
Validation loss decreased (1.014043 --> 0.952794).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 3 | loss: 0.2453511
	speed: 0.0676s/iter; left time: 853.7356s
	iters: 200, epoch: 3 | loss: 0.0951574
	speed: 0.0170s/iter; left time: 212.5532s
Epoch: 3 cost time: 5.732691764831543
Epoch: 3, Steps: 265 | Train Loss: 0.1210310 Vali Loss: 0.9237788 Test Loss: 0.5514063
Validation loss decreased (0.952794 --> 0.923779).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 4 | loss: 0.0778819
	speed: 0.0527s/iter; left time: 651.5874s
	iters: 200, epoch: 4 | loss: 0.2246984
	speed: 0.0122s/iter; left time: 148.9643s
Epoch: 4 cost time: 3.8681299686431885
Epoch: 4, Steps: 265 | Train Loss: 0.1177260 Vali Loss: 0.8898416 Test Loss: 0.5282149
Validation loss decreased (0.923779 --> 0.889842).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 5 | loss: 0.0751880
	speed: 0.0597s/iter; left time: 721.8655s
	iters: 200, epoch: 5 | loss: 0.0784752
	speed: 0.0215s/iter; left time: 257.6027s
Epoch: 5 cost time: 5.852907657623291
Epoch: 5, Steps: 265 | Train Loss: 0.1146539 Vali Loss: 0.8455965 Test Loss: 0.5070379
Validation loss decreased (0.889842 --> 0.845596).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 6 | loss: 0.0923322
	speed: 0.0619s/iter; left time: 731.7127s
	iters: 200, epoch: 6 | loss: 0.0845313
	speed: 0.0210s/iter; left time: 245.9868s
Epoch: 6 cost time: 5.855632305145264
Epoch: 6, Steps: 265 | Train Loss: 0.1070277 Vali Loss: 0.8306502 Test Loss: 0.4938381
Validation loss decreased (0.845596 --> 0.830650).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 7 | loss: 0.0946268
	speed: 0.0607s/iter; left time: 701.9035s
	iters: 200, epoch: 7 | loss: 0.0838162
	speed: 0.0199s/iter; left time: 228.0729s
Epoch: 7 cost time: 5.668521404266357
Epoch: 7, Steps: 265 | Train Loss: 0.1055369 Vali Loss: 0.8356564 Test Loss: 0.4813307
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 8 | loss: 0.0957569
	speed: 0.0585s/iter; left time: 660.2746s
	iters: 200, epoch: 8 | loss: 0.1203984
	speed: 0.0135s/iter; left time: 151.6079s
Epoch: 8 cost time: 4.269786357879639
Epoch: 8, Steps: 265 | Train Loss: 0.1030502 Vali Loss: 0.8010156 Test Loss: 0.4706554
Validation loss decreased (0.830650 --> 0.801016).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 9 | loss: 0.0864788
	speed: 0.0495s/iter; left time: 546.2137s
	iters: 200, epoch: 9 | loss: 0.0814191
	speed: 0.0200s/iter; left time: 218.3624s
Epoch: 9 cost time: 5.805050373077393
Epoch: 9, Steps: 265 | Train Loss: 0.1035953 Vali Loss: 0.7813135 Test Loss: 0.4626418
Validation loss decreased (0.801016 --> 0.781314).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 10 | loss: 0.2491599
	speed: 0.0620s/iter; left time: 667.8155s
	iters: 200, epoch: 10 | loss: 0.0721091
	speed: 0.0193s/iter; left time: 206.1934s
Epoch: 10 cost time: 5.519763708114624
Epoch: 10, Steps: 265 | Train Loss: 0.1007873 Vali Loss: 0.7790377 Test Loss: 0.4594799
Validation loss decreased (0.781314 --> 0.779038).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 11 | loss: 0.0941226
	speed: 0.0616s/iter; left time: 646.6502s
	iters: 200, epoch: 11 | loss: 0.0827708
	speed: 0.0199s/iter; left time: 206.5688s
Epoch: 11 cost time: 5.6547768115997314
Epoch: 11, Steps: 265 | Train Loss: 0.0971137 Vali Loss: 0.7618500 Test Loss: 0.4535955
Validation loss decreased (0.779038 --> 0.761850).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 12 | loss: 0.0729789
	speed: 0.0587s/iter; left time: 600.3835s
	iters: 200, epoch: 12 | loss: 0.0838058
	speed: 0.0190s/iter; left time: 192.2427s
Epoch: 12 cost time: 5.0763726234436035
Epoch: 12, Steps: 265 | Train Loss: 0.1021239 Vali Loss: 0.7797460 Test Loss: 0.4579933
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 13 | loss: 0.0720310
	speed: 0.0434s/iter; left time: 432.7744s
	iters: 200, epoch: 13 | loss: 0.0907066
	speed: 0.0190s/iter; left time: 187.6547s
Epoch: 13 cost time: 5.0388007164001465
Epoch: 13, Steps: 265 | Train Loss: 0.0962763 Vali Loss: 0.7554339 Test Loss: 0.4494555
Validation loss decreased (0.761850 --> 0.755434).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 14 | loss: 0.0759623
	speed: 0.0620s/iter; left time: 601.3621s
	iters: 200, epoch: 14 | loss: 0.0829824
	speed: 0.0183s/iter; left time: 176.1283s
Epoch: 14 cost time: 5.594855785369873
Epoch: 14, Steps: 265 | Train Loss: 0.0967917 Vali Loss: 0.7683287 Test Loss: 0.4485793
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 15 | loss: 0.0873469
	speed: 0.0638s/iter; left time: 601.8803s
	iters: 200, epoch: 15 | loss: 0.0680932
	speed: 0.0213s/iter; left time: 198.9413s
Epoch: 15 cost time: 5.768960475921631
Epoch: 15, Steps: 265 | Train Loss: 0.0960085 Vali Loss: 0.7387352 Test Loss: 0.4481311
Validation loss decreased (0.755434 --> 0.738735).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 16 | loss: 0.0727385
	speed: 0.0612s/iter; left time: 561.9408s
	iters: 200, epoch: 16 | loss: 0.0972294
	speed: 0.0171s/iter; left time: 154.7836s
Epoch: 16 cost time: 5.261036396026611
Epoch: 16, Steps: 265 | Train Loss: 0.0962024 Vali Loss: 0.7459287 Test Loss: 0.4498859
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 17 | loss: 0.0821681
	speed: 0.0470s/iter; left time: 418.8425s
	iters: 200, epoch: 17 | loss: 0.2469507
	speed: 0.0123s/iter; left time: 108.4612s
Epoch: 17 cost time: 3.7544820308685303
Epoch: 17, Steps: 265 | Train Loss: 0.1021603 Vali Loss: 0.7450348 Test Loss: 0.4828730
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 18 | loss: 0.0820432
	speed: 0.0549s/iter; left time: 474.7404s
	iters: 200, epoch: 18 | loss: 0.2668930
	speed: 0.0158s/iter; left time: 135.3875s
Epoch: 18 cost time: 4.912794828414917
Epoch: 18, Steps: 265 | Train Loss: 0.1050078 Vali Loss: 0.7262134 Test Loss: 0.4632162
Validation loss decreased (0.738735 --> 0.726213).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 19 | loss: 0.0889967
	speed: 0.0531s/iter; left time: 444.7611s
	iters: 200, epoch: 19 | loss: 0.1633941
	speed: 0.0164s/iter; left time: 135.8319s
Epoch: 19 cost time: 4.914660692214966
Epoch: 19, Steps: 265 | Train Loss: 0.1006637 Vali Loss: 0.7524088 Test Loss: 0.4499122
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 20 | loss: 0.0884426
	speed: 0.0495s/iter; left time: 401.9907s
	iters: 200, epoch: 20 | loss: 0.0692984
	speed: 0.0146s/iter; left time: 117.4015s
Epoch: 20 cost time: 4.046395778656006
Epoch: 20, Steps: 265 | Train Loss: 0.0982673 Vali Loss: 0.7363123 Test Loss: 0.4437549
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 21 | loss: 0.0755015
	speed: 0.0343s/iter; left time: 269.4702s
	iters: 200, epoch: 21 | loss: 0.2446771
	speed: 0.0123s/iter; left time: 95.2973s
Epoch: 21 cost time: 3.851550340652466
Epoch: 21, Steps: 265 | Train Loss: 0.0969506 Vali Loss: 0.7487734 Test Loss: 0.4394915
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 22 | loss: 0.0682309
	speed: 0.0529s/iter; left time: 401.2501s
	iters: 200, epoch: 22 | loss: 0.0726480
	speed: 0.0185s/iter; left time: 138.6646s
Epoch: 22 cost time: 5.256741762161255
Epoch: 22, Steps: 265 | Train Loss: 0.0958091 Vali Loss: 0.7279694 Test Loss: 0.4365266
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 23 | loss: 0.1142726
	speed: 0.0634s/iter; left time: 464.5170s
	iters: 200, epoch: 23 | loss: 0.0736551
	speed: 0.0195s/iter; left time: 141.0588s
Epoch: 23 cost time: 5.68641209602356
Epoch: 23, Steps: 265 | Train Loss: 0.0932137 Vali Loss: 0.7175363 Test Loss: 0.4381647
Validation loss decreased (0.726213 --> 0.717536).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 24 | loss: 0.2066385
	speed: 0.0612s/iter; left time: 432.0630s
	iters: 200, epoch: 24 | loss: 0.0735027
	speed: 0.0179s/iter; left time: 124.2890s
Epoch: 24 cost time: 5.262205600738525
Epoch: 24, Steps: 265 | Train Loss: 0.0938591 Vali Loss: 0.7175087 Test Loss: 0.4330999
Validation loss decreased (0.717536 --> 0.717509).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 25 | loss: 0.0769373
	speed: 0.0447s/iter; left time: 303.4740s
	iters: 200, epoch: 25 | loss: 0.1003132
	speed: 0.0130s/iter; left time: 86.8139s
Epoch: 25 cost time: 4.16297173500061
Epoch: 25, Steps: 265 | Train Loss: 0.0897065 Vali Loss: 0.7084027 Test Loss: 0.4311683
Validation loss decreased (0.717509 --> 0.708403).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 26 | loss: 0.0873605
	speed: 0.0623s/iter; left time: 406.3229s
	iters: 200, epoch: 26 | loss: 0.0833419
	speed: 0.0193s/iter; left time: 124.2587s
Epoch: 26 cost time: 5.631860017776489
Epoch: 26, Steps: 265 | Train Loss: 0.0891383 Vali Loss: 0.7253248 Test Loss: 0.4286317
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 27 | loss: 0.0693894
	speed: 0.0632s/iter; left time: 395.6305s
	iters: 200, epoch: 27 | loss: 0.0758500
	speed: 0.0217s/iter; left time: 133.5464s
Epoch: 27 cost time: 5.831871509552002
Epoch: 27, Steps: 265 | Train Loss: 0.0947122 Vali Loss: 0.7174156 Test Loss: 0.4293328
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 28 | loss: 0.0966377
	speed: 0.0633s/iter; left time: 379.3755s
	iters: 200, epoch: 28 | loss: 0.0661294
	speed: 0.0197s/iter; left time: 116.1619s
Epoch: 28 cost time: 5.460952043533325
Epoch: 28, Steps: 265 | Train Loss: 0.0928934 Vali Loss: 0.7212256 Test Loss: 0.4273481
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 29 | loss: 0.0812854
	speed: 0.0523s/iter; left time: 299.4811s
	iters: 200, epoch: 29 | loss: 0.0971361
	speed: 0.0125s/iter; left time: 70.4536s
Epoch: 29 cost time: 3.9536337852478027
Epoch: 29, Steps: 265 | Train Loss: 0.0917616 Vali Loss: 0.7051033 Test Loss: 0.4252693
Validation loss decreased (0.708403 --> 0.705103).  Saving model ...
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 30 | loss: 0.1929502
	speed: 0.0540s/iter; left time: 295.4228s
	iters: 200, epoch: 30 | loss: 0.0967404
	speed: 0.0200s/iter; left time: 107.2880s
Epoch: 30 cost time: 5.660513639450073
Epoch: 30, Steps: 265 | Train Loss: 0.0914972 Vali Loss: 0.7159181 Test Loss: 0.4242218
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 31 | loss: 0.0680413
	speed: 0.0615s/iter; left time: 319.7618s
	iters: 200, epoch: 31 | loss: 0.0773056
	speed: 0.0208s/iter; left time: 105.8702s
Epoch: 31 cost time: 5.8289642333984375
Epoch: 31, Steps: 265 | Train Loss: 0.0912986 Vali Loss: 0.7233743 Test Loss: 0.4283872
EarlyStopping counter: 2 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 32 | loss: 0.0747107
	speed: 0.0644s/iter; left time: 317.6926s
	iters: 200, epoch: 32 | loss: 0.0813499
	speed: 0.0198s/iter; left time: 95.7611s
Epoch: 32 cost time: 5.68358588218689
Epoch: 32, Steps: 265 | Train Loss: 0.0927316 Vali Loss: 0.7227442 Test Loss: 0.4257414
EarlyStopping counter: 3 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 33 | loss: 0.0726216
	speed: 0.0604s/iter; left time: 282.3090s
	iters: 200, epoch: 33 | loss: 0.0647385
	speed: 0.0154s/iter; left time: 70.5951s
Epoch: 33 cost time: 4.591947317123413
Epoch: 33, Steps: 265 | Train Loss: 0.0931405 Vali Loss: 0.7158118 Test Loss: 0.4221287
EarlyStopping counter: 4 out of 5
Updating learning rate to 0.0001
Memory is all updated
	iters: 100, epoch: 34 | loss: 0.0780438
	speed: 0.0484s/iter; left time: 213.2854s
	iters: 200, epoch: 34 | loss: 0.0746224
	speed: 0.0206s/iter; left time: 88.6128s
Epoch: 34 cost time: 5.644836187362671
Epoch: 34, Steps: 265 | Train Loss: 0.0939659 Vali Loss: 0.7118973 Test Loss: 0.4191723
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : long_term_forecast_ETTh1_96_96_DLinear_ETTh1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0_fm_rag<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.42527952790260315, mae:0.4333077669143677, dtw:Not calculated
